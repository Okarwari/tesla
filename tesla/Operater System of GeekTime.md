### Test

1. ABC 对D不太理解，没有使用过
2. ABC 
3. B
4. 
5. BC
6. A
7. BC
8. BD
9. C
10.
11. AD
12. BD

### 推荐书籍
OSTEP(Operating System Three Easy Picies)
Unix/Linux编程实践教程(Understanding UNIX/LINUX Programming)
csapp深入理解计算机系统
ProgrammingwithPOSIXThreads


一个操作系统的实现
### 趣谈操作系统中的外包对应名词
* 项目运行体系 -- 祖宗进程
* 会议室 -- 内存
* 会议室管理系统 -- 内存管理系统
* 项目执计划书 -- 代码段
* 会议记录 -- 数据段
* 
    



### 从入门到放弃-- Linux六大山坡
#### 第一个坡： 抛弃旧的思维习惯， 熟练使用Linux命令行
    鸟哥的Linux私房菜
    LInux系统管理技术手册
#### 第二个坡：通过系统调用或者 glibc，学会自己进行程序设计
    UNIX环境高级编程

#### 



### 1 基本Linux命令
![](https://static001.geekbang.org/resource/image/88/e5/8855bb645d8ecc35c80aa89cde5d16e5.jpg)


###  2 部分系统调用
#### 进程管理（立项服务）
1. Linux中父进程调用fork创建子进程。
2. 父进程调用fork时，子进程拷贝所有父进程的数据接口和代码过来。
3. 当前进程是子进程，fork返回0；当前进程是父进程，fork返回子进程进程号
4. 如果返回0，说明当前进程是子进程，子进程请求execve系统调用，执行另一个程序。
5. 如果返回子进程号，说明当前进程是父进程，按照原父进程原计划执行。
6. 父进程要对子进程负责，调用waitpid将子进程进程号作为参数，父进程就能知道子进程运行完了没有，成功与否。
7. 操作系统启动的时候先创建了一个所有用户进程的“祖宗进程”，课时1，第3题A选项：0号进程是所有用户态进程的祖先
* fork 创建进程
* execve 执行另一个程序的系统调用
* waitpid 父进程调用判断子进程是否执行完毕
#### 内存管理（会议室管理）
* brk 分配连续小内存
* mmap 分配连续大内存
#### 文件管理（档案资料库管理）
一切皆是文件： （程序文件（二进制文件）、文本文件、标准输入输出文件、管道文件、
Socket、设备、文件夹等皆是文件
* open 打开文件
* close 关闭文件
* creat 创建文件
* lseek 跳到文件的指定位置
* read 文件读取
* write 文件写入

![](https://static001.geekbang.org/resource/image/e4/df/e49b5c2a78ac09903d697126bfe6c5df.jpeg)

#### 信号处理
* kill 终止一个进程
* sigaction 注册一个信号处理函数

####  进程通信（项目间沟通）
当进程间发送较小的信息时，使用消息队列方式，消息队列存在于内核中
* msgget 创建一个新的队列
* msgsnd 将消息发送到消息队列
* msgrcv 从队列中读取消息
当进程间需要交互的信息较大时，使用共享内存的方式，即两个项目共享了一个会议室
* shmget 创建一个共享内存块
* shmat 将共享内存映射到自己的内存控件，就可以开始读写
注： 共享内存需要注意数据竞争问题（两个进程同时读写数据），由此引出信号量机制

信号量机制Semaphore
>对于只允许一个人访问的需求，我们可以将信号量设为 1。当一个人要访问的时候，
先调用sem_wait。如果这时候没有人访问，则占用这个信号量，他就可以开始访问了。
如果这个时候另一个人要访问，也会调用 sem_wait。由于前一个人已经在访问了，
所以后面这个人就必须等待上一个人访问完之后才能访问。当上一个人访问完毕后，
会调用sem_post将信号量释放，于是下一个人等待结束，可以访问这个资源了。

#### 网络通信（公司间沟通）
不同机器间进行网络通信，需要遵循相同的网络协议,即TCP/IP网络协议栈。
Linux内核实现了网络协议栈

网络服务是通过Socket来提供服务的。Socket可以比作一个插槽，双方通信之间都需要建立一个Socket
Socket，也是一个文件，也有一个文件描述符。

#### 查看源代码的系统调用

unistd_64.h
```
#define __NR_restart_syscall	  0
#define __NR_exit		  1
#define __NR_fork		  2
#define __NR_read		  3
#define __NR_write		  4
#define __NR_open		  5
#define __NR_close		  6
#define __NR_waitpid		  7
#define __NR_creat		  8
......

```

#### glibc
##### glibc是Linux下开源标准C库
##### glibc把系统调用进一步封装

##### sys_open对应glibc的open函数
##### 一个单独的glibcAPI可能调用多个系统调用
##### printf函数调用sys_open、sys_mmap、sys_write、sys_close等等系统调用


#### 总结系统调用图
![](../assets/images/系统调用命令.jpg)    




 



### 3 X86体系架构
- CPU 包括: 运算单元, 数据单元, 控制单元
    - 运算单元 不知道算哪些数据, 结果放哪
    - 数据单元 包括 CPU 内部缓存和寄存器, 暂时存放数据和结果
    - 控制单元 获取下一条指令, 指导运算单元取数据, 计算, 存放结果
- 进程包含代码段, 数据段等, 以下为 CPU 执行过程:
    - 控制单元 通过指令指针寄存器(IP), 取下一条指令, 放入指令寄存器中
        - 指令包括操作和目标数据
    - 数据单元 根据控制单元的指令, 从数据段读数据到数据寄存器中
    - 运算单元 开始计算, 结果暂时存放到数据寄存器
- 两个寄存器, 存当前进程代码段和数据段起始地址, 在进程间切换
- 总线包含两类数据: 地址总线和数据总线
---
- x86 开放, 统一, 兼容
- 数据单元 包含 8个 16位通用寄存器, 可分为 2个 8位使用
- 控制单元 包含 IP(指令指针寄存器) 以及 4个段寄存器 CS DS SS ES
    - IP 存放指令偏移量
    - 数据偏移量存放在通用寄存器中
    - `段地址<<4 + 偏移量` 得到地址
---
- 32 位处理器
- 通用寄存器 从 8个 16位拓展为 8个 32位, 保留 16位和 8位使用方式
- IP 从 16位扩展为 32位, 保持兼容
- 段寄存器仍为 16位, 由段描述符(表格, 缓存到 CPU 中)存储段的起始地址, 由段寄存器选择其中一项
    - 保证段地址灵活性与兼容性
---
- 16位为实模式, 32位为保护模式
- 刚开机为实模式, 需要更多内存切换到保护模式


## 进程管理
### 线程的并发执行
#### 为什么要有线程?
将任务拆解，同时运行。
#### 如何创建线程?
![](../assets/images/线程的创建过程.jpg)
#### 线程的数据
我们将线程访问的数据分为三类
1. 线程上的本地数据，比如函数内创建的局部变量
2. 进程里的共享的全局变量
3. 线程里创建的私有变量
>int pthread_key_create(pthread_key_t *key, void (*destructor)(void*))
![](../assets/images/线程的数据.jpg)

#### 数据的保护
多线程如何操作共享数据，并保证数据的一致性和准确性
1. Mutex(Mutual Exclusion)，中文名叫互斥。即通过一把互斥锁，多个线程同时去
抢占这把锁，线程A抢占成功则继续运行，其他线程如线程B抢占失败则阻塞直到线程A释放互斥锁。
![](../assets/images/Mutex的使用流程.jpg)
2. 条件变量和互斥锁。再没有任务是，多个线程都处于休眠状态，一旦任务出现，会对应通知其他休眠线程，
线程则开始抢占任务，抢占成功则继续运行，抢占失败则继续进行休眠。知道下次任务出现发出通知
![](../assets/images/条件变量和互斥锁（被动通知模式）.jpeg)
什么需要条件变量？互斥锁本身好像就能保护数据不被篡改和破坏。

其实，互斥所的确能够保证数据的准确性，只是，他再某些条件下会造成CPU的消耗。

假设有这么一个场景：

有一个任务队列，里面存储这若干任务。有ABCD四个线程需要轮流从任务队列里取出任务来执行。
生产任务者会不定期向任务队列里添加任务。这是怎样做能够保证同一个任务不被两个人同时领取？

第一肯定是上锁，拿到锁的线程操作任务队列取出数据后释放锁，由下个线程加锁从队列中获取数据。
这样能够保证每个任务只有一个线程再运行，从而起到保护效果。但是，当任务队列里面没有任务，
而空闲线程会不断的处于获取锁，查看任务队列，没有任务，释放锁的过程，这样会消耗CPU的资源。

第二个解决办法就是，加上条件变量。开始时操作相同，多个线程抢占锁，拿到锁的线程
操作任务队列取出数据后释放锁，由下个线程加锁从队列中获取数据。当某个线程抢占锁后发现没有任务，
则进入休眠并释放锁，等待生产者重新向任务队列添加任务。其他线程任务执行完毕后同样再次抢占锁
查看任务队列，发现没有任务后同样进入释放锁进入休眠状态。当生产者添加任务时，同时唤醒休眠线程
继续抢占锁来处理任务。

第二个解决办法实际上时处于被动通知的状态，再没有任务时所有的线程都处于休眠，降低了占用CPU的时间
从而提高了利用率，而第一种方法则会不断的主动判断任务队列是否有任务，处于不断加锁，检查条件，释放锁
的过程，占用了CPU。导致效率低下。

#### 总结
1. 当操作共享数据，一定要使用锁。
2. 当不定时出现任务时，可以时用条件变量加互斥锁，被动通知的去处理任务
3. 条件变量的使用应该也是有场景的，它主要是为了避免线程一直竞争锁而导致cpu占用高，
但是它也是有代价的，线程被唤醒也是要消耗cpu资源的。其实如果老板一直发任务，
不会间隔很长时间才发新任务的话，只用互斥锁就可以了
4. 线程的使用总结
![](../assets/images/线程的使用总结.png)
